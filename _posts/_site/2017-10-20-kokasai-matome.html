<p>LinuxClubの1年のKoyamaです。</p>

<p>今後、このブログを通じてサークルの活動の様子を積極的に発信していきたいと思います。この記事では2017年度 紅華祭を振り返ってみたいと思います。まず、部長から全体を通したコメントです。</p>

<h2 id="全体を通じて">全体を通じて</h2>

<p>前日に完成している展示物がなくて焦ったものですがみなさんいいものを作ってきてくれて驚きました。普段コンソールに向かっているので見栄えのいいものと言われても困ったとは思いますが良い作品を展示できてよかったです。</p>

<h2 id="個人制作">個人制作</h2>

<p>1,2年生を中心に個人作品を制作しました。<code class="highlighter-rouge">作品名 [作者]</code>という形式で見出しをつけています。</p>

<h3 id="1-空飛ぶ絨毯-koyama">1. 空飛ぶ絨毯 [Koyama]</h3>

<p>Webカメラで取得した映像とあらかじめ用意した動画をクロマキー合成するプログラムを作成し、展示しました。使用した言語は<code class="highlighter-rouge">Python</code>でライブラリは<code class="highlighter-rouge">OpenCV</code>を使用しました。以下の記事を参考にしながらコードを書きました。</p>

<ul>
  <li><a href="https://www.blog.umentu.work/python-opencv3%E3%81%A7%E7%94%BB%E5%83%8F%E3%81%AE%E7%94%BB%E7%B4%A0%E5%80%A4%E3%82%92%E4%BA%8C%E5%80%A4%E5%8C%96%E3%81%97%E3%81%A6%E5%87%BA%E5%8A%9B/">Python OpenCV3で画像の画素値を二値化して出力 | from umentu import stupid</a></li>
  <li><a href="http://make.kosakalab.com/rpi/opencv_3/">RPi + Python + OpenCV その３「クロマキー」 | OpenCV | kosakalab</a></li>
  <li><a href="http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html">Getting Started with Videos — OpenCV-Python Tutorials 1 documentation</a></li>
</ul>

<p>ソースコードは以下です。</p>

<script src="https://gist.github.com/tomoyk/698c6294637b16b140da404854e37389.js"></script>

<p>途中でOpenCVのエラーで終了してしまうのでシェル芸で回避しました。パラメータを変えることで背景の動画を変更できる機能も実装してうまく連携させました。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>while true
do
  for foo in {1..3}
  do
    python3 origin.py $foo
  done
done
</code></pre>
</div>

<p>実際に動かすと以下のようになります。</p>

<p><img src="https://pbs.twimg.com/media/DLlmyHjUIAAnZ7c.jpg:large" width="500" /></p>

<p><img src="/images/kokasai2017/koyama_screenshot.jpg" width="300" /></p>

<h3 id="2-移植版ドアセンサー-koyama">2. 移植版ドアセンサー [Koyama]</h3>

<p>サークルの部室にドアが開くと音が鳴る謎のシステム(Raspi + スピーカ)を作りました。その移植版をArduino UNOとProcessingを使って作成しました。センサーは秋月電子で販売されているドア用センサーを使いました。</p>

<p><a href="http://akizukidenshi.com/catalog/g/gP-04025/">ケース入りリードスイッチ（磁石付セット）ＭＣ－１４ＡＧ: センサ一般 秋月電子通商 電子部品 ネット通販</a></p>

<p>Arduinoには次の回路を実装しました。</p>

<p><img src="https://raw.githubusercontent.com/tomoyk/kokasai17/master/proc_testVisualizer/images/architecture.jpg" width="500" /></p>

<p>次にArduinoへ以下のプログラムを書き込みます。このプログラムではdigital 7番ピンに接続されたセンサーの値を取得してシリアルに書き出す処理を行っています。<code class="highlighter-rouge">delay(100)</code>によって遅延処理を行っています。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>#define SENSOR_PIN 7

void setup(){
  Serial.begin(9600);
}

void loop(){
  int val = digitalRead(SENSOR_PIN);
  Serial.write(val);
  delay(100);
}
</code></pre>
</div>

<p>Arduinoにプログラムが書き込めているかシリアルモニタを使って確認します。</p>

<p>次にProcessingを起動します。そして、以下のプログラムを入力します。</p>

<script src="https://gist.github.com/tomoyk/f67947c7f7913bde2ec0db272487e5e8.js"></script>

<p>プログラムの概要について説明します。</p>

<ul>
  <li>プログラム先頭の<code class="highlighter-rouge">import processing.sound.*;</code>ではあらかじめインストールしたサウンドを再生するライブラリを読み込んでいます。</li>
  <li>その後にある<code class="highlighter-rouge">boolean</code>や<code class="highlighter-rouge">PImage</code>や<code class="highlighter-rouge">Soundfile</code>ではセンサーの状態、画像ファイル、音声ファイルを保持する変数を宣言しています。</li>
  <li><code class="highlighter-rouge">setup()</code>ではシリアル、画像、音声の初期化を行っています。</li>
  <li><code class="highlighter-rouge">setBack()</code>では背景を設定しています。</li>
  <li><code class="highlighter-rouge">draw()</code>ではセンサーの値に応じてドアが開いているか、閉じているかを判断しています。また、その状況に応じて画像や音声を切り替えています。</li>
</ul>

<p>次に画像ファイルと音声ファイルを用意します。</p>

<p>画像はいらすとやから入手しました。</p>

<p><a href="http://www.irasutoya.com/2016/07/blog-post_832.html">いろいろな状態のドアのイラスト | かわいいフリー素材集 いらすとや</a></p>

<p>ダウンロードした画像ファイルのドアが揃うようにGIMPで調整しました。そして、ファイル名を<code class="highlighter-rouge">door_close.png</code>と<code class="highlighter-rouge">door_open.png</code>にリネームします。</p>

<p>音声は音声合成システム<strong>Open JTalk</strong>を使用して作成しました。今回は一時的な使用だった為、Dockerを使いました。</p>

<p><a href="https://hub.docker.com/r/yamamotofebc/open_jtalk/">yamamotofebc/open_jtalk - Docker Hub</a></p>

<p>まず、イメージを入手します。</p>

<p><code class="highlighter-rouge">docker pull yamamotofebc/open_jtalk</code></p>

<p>次にリファレンスに従って生成したい文字列を設定してコマンドを実行します。単純な読み上げにしか対応していないので<code class="highlighter-rouge">こんにちは</code>を<code class="highlighter-rouge">こんにちわ</code>として設定しています。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>echo "こんにちわ" | docker run -i --rm yamamotofebc/open_jtalk &gt; door_hello.wav
echo "ばいばいきん" | docker run -i --rm yamamotofebc/open_jtalk &gt; door_close.wav
</code></pre>
</div>

<p>これらの準備が終わったらProcessingのIDEに戻って実行ボタンを押下します。LinuxではIDEをroot権限で起動しないとシリアルデバイスにアクセスできないので注意が必要です。</p>

<p>うまく動作すればドアセンサーが離れたときに画面上にドアが開いている画像が表示され、「こんにちは」という音声が流れます。</p>

<p><img src="https://raw.githubusercontent.com/tomoyk/kokasai17/master/proc_testVisualizer/images/demoOpen.jpg" width="300" />
<img src="https://raw.githubusercontent.com/tomoyk/kokasai17/master/proc_testVisualizer/images/demoClose.jpg" width="300" /></p>

<h3 id="3-物体認識-部長">3. 物体認識 [部長]</h3>
<p>DarkNetを使った物体認識ソフトウェアを作りました。
基本的な構造としては<code class="highlighter-rouge">Docker</code>を使い、<code class="highlighter-rouge">フロントエンド</code>、<code class="highlighter-rouge">バックエンド</code>、<code class="highlighter-rouge">静的ファイルの配信サーバー</code>という形で構築し、AWS上で動作させていました。</p>

<p>※<code class="highlighter-rouge">DarkNet</code>とはC言語で書かれた機械学習ライブラリです。学習済みデータが公開されているので画像をぶん投げるだけで解析してくれる優れものです。</p>

<h4 id="フロントエンド">フロントエンド</h4>
<p>使用ライブラリ</p>
<div class="highlighter-rouge"><pre class="highlight"><code>- React
- Recompose
- Material UI
</code></pre>
</div>

<p>フロントエンドではES6に<code class="highlighter-rouge">React</code>, <code class="highlighter-rouge">Recompose</code>を使いました。
来場者にアクセスさせて写真をアップロード、解析した写真を表示する機能しか必要なかったのですが無駄にモダンな構成になっています。特筆することはないです。</p>

<h4 id="バックエンド">バックエンド</h4>
<p>使用ライブラリ</p>
<div class="highlighter-rouge"><pre class="highlight"><code>- PIL (画像処理)
- falcon (APIサーバー)
</code></pre>
</div>

<p>バックエンドはpythonで書きました。falconでルーティングしてDarkNetに投げるなどの役割を担っています。</p>

<p>PILはiphoneから投げられた画像に対して処理をしています。画像は主にEXIFと呼ばれる情報の格納部分があり、そこにOrientationという画像の向きを保持する情報があります。iphoneで撮影された画像はその部分が常にright-topという横向きの状態で保持されるらしく、PILを使って画像を縦向きに回転して保存する処理をしてます。</p>

<p>PILは</p>
<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
<span class="n">exif</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">_getexif</span><span class="p">()</span>
<span class="n">orientation</span> <span class="o">=</span> <span class="n">exif</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="mh">0x112</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">img</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">original_filename</span><span class="p">)</span>

</code></pre>
</div>
<p>とかするとexifをスッととってこれて楽でよかったです。</p>

<h4 id="静的ファイルの配信サーバー">静的ファイルの配信サーバー</h4>
<p>nginxでDarkNetで書き出された画像を配信してるだけです。特筆事項なし。</p>

<h4 id="反省など">反省など</h4>
<p>色々ばたついてて作り始めるのが遅かったせいで大したものが作れなかったのが心残りです。それとDarkNetをDockerの上に載せていたせいでレスポンスがだいぶ悪くなってしまいました。workerも4つしか動かしておらずお世辞にも十分だったとは言えない感じです。来年はGTX TITANとか買って望みたいです。嘘です。</p>

<h3 id="4-opencvのチュートリアル-homirun">4. OpenCVのチュートリアル [homirun]</h3>

<p>Webカメラで撮影された動画をリアルタイムでカスケード分類器を用い顔認識させてみました。
顔を検出してその上に某氏の画像をオーバーレイしました。
PyConの日に作りました。</p>

<p>使用ライブラリ</p>
<ul>
  <li>OpenCV</li>
  <li>numpy</li>
  <li>pyplot</li>
</ul>

<p><img src="/images/kokasai2017/homirun_screenshot.png" width="500" /></p>

<script src="https://gist.github.com/homirun/035f39415f9d976f9da86ffe2632519f.js"></script>

<h3 id="5-声でツイートできるプログラム-panakuma">5. 声でツイートできるプログラム [panakuma]</h3>

<p>　音声認識で録音した音声をテキストに起こして、ツイッターにポストするプログラムです。言語はPythonで、音声認識はGoogle Cloud APIを使いました。</p>

<p>ソースコードは以下です。</p>

<h4 id="全体の実行スクリプト">全体の実行スクリプト</h4>

<script src="https://gist.github.com/kumapana/1f492a0cd948896eb090b28ac14c32a1.js"></script>

<h4 id="google-apiを叩くソース">Google APIを叩くソース</h4>

<script src="https://gist.github.com/kumapana/1f492a0cd948896eb090b28ac14c32a1.js"></script>

<h4 id="ツイッターに投げるソース">ツイッターに投げるソース</h4>

<script src="https://gist.github.com/kumapana/be3eb1e828384f427d00349dfe387117.js"></script>

<h4 id="ハマった点">ハマった(?)点</h4>

<p>Google Cloud APIから吐かれるjsonファイルの取り扱いで1日ほどハマってました。(最終的にK氏に解決していただいた)</p>

<p>当初の予定では、京都大学 河原研究室が開発したJuliusという音声認識システムを使う予定でしたが、認識精度が低かったため、Google APIに投げることにしました。</p>

<h3 id="6-cpu-use-rate-lapua">6. CPU use rate [lapua]</h3>

<p>CPU使用率をリアルタイムで表示するGUIアプリ。16コアまで対応。使用ライブラリはQt5.0.0
初めてのクラス設計に苦労しました。</p>

<p><img src="/images/kokasai2017/lapua_screenshot.png" width="500" /></p>

<h3 id="7-数当てゲーム-ayu">7. 数当てゲーム [ayu]</h3>

<p>コンソールから入力された数字に対して当ってるだの当ってないだの評価して返す簡単なゲーム．Javaで書きました．GUI化させていきたい．</p>

<p><img src="/images/kokasai2017/ayu_screenshot.png" width="500" /></p>

<h3 id="8-目覚まし-uwdd">8. 目覚まし [uwdd]</h3>

<p>今回初めて<del>まともな</del>プログラミング作品を作りました。朝起きれなくて遅刻が増えてきたので今回は目覚まし時計を作りました。まだいくつか不具合があったりデザインが簡素すぎたりするので暇があれば直していきたい。</p>

<p><img src="/images/kokasai2017/uwdd_screenshot.png" width="500" /></p>

<h2 id="毎年恒例のlc-ob会">毎年恒例?のLC OB会</h2>

<p>LinuxClubの歴史は長いらしく、古くはLinux研究所という名前だったそうです。</p>

<p>学祭で社会人OBが集まるということが恒例になっているようです。OBと現役生の交流の場になっていました。</p>

<h2 id="2日目から始まったライブ中継">2日目から始まったライブ中継</h2>

<p>2日目から先輩のカメラでライブ中継を行いました。</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/KyDryF34rFQ?rel=0" frameborder="0" allowfullscreen=""></iframe>

<h2 id="大学からの取材">大学からの取材</h2>

<p>大学の広報から取材を受けました。何かしらの映像で公開されるかと思われます。おそらく、紹介動画かと思われます。</p>

<p><a href="http://www.teu.ac.jp/student/006532.html">学園祭（紅華祭・かまた祭）[2017年] | 学生生活 | 東京工科大学</a></p>

<h2 id="来年に向けて">来年に向けて</h2>

<p>展示品の数が少なかったので来年はもっと数を増やすべきだと思いました。来場された方が見て分かるよう説明を加えるなど「何を、どのように実現しているか」を明確にする必要があると感じました。</p>

<p>また、来場された方から「今年は冊子を作ってないんですか？」と聞かれることがあったので来年は部誌のような冊子を作成したいと思います。</p>

<p><strong>来場して頂きありがとうございました。ぜひ来年もお越しください!!</strong></p>

